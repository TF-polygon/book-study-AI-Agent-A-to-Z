# 4장: LLM으로 웹 스크래핑 에이전트 구축하기

핵심 주제: LLM의 능력을 확장해 외부 세계와 상호작용할 수 있는 AI 에이전트 구축 방법 탐구. LLM을 '상자 밖으로 꺼내' 웹에서 정보를 검색하고, 실제 세계의 데이터를 기반으로 작동하게 만드는 방법을 다룬다.

- 두뇌, 지각, 행동 패러다임 이해하기
- AI 에이전트 분류하기
- 단일 에이전트와 다중 에이전트 시스템 이해하기
- 주요 라이브러리 탐구
- 단일 에이전트의 일반 능력
- 웹 검색 에이전트 만들기

## 1. 두뇌, 지각, 행동 패러다임 이해하기

|구분|정의|해석|
|----|----|--|
|Agent|행동할 수 있는 능력을 지닌 실체|욕망, 신념, 의도 등을 포함해 보다 복잡한 존재로 해석|
|AI Agent|행동을 수행할 수 있는 시스템|철학에서 사용하는 표현하는 Agent와는 다른 의미. LLM에 '의식이 있다'고 주장하는 것은 인간 중심적 오류에 해당|

**AI Agent**는 일련의 센서를 통해 주변 환경을 인지하고, 그에 따라 판단을 내리며, 이를 실행하는 인공적 실체로 정의할 수 있다.

### 1.1. AI Agent Framework

|구성 요소|설명|
|---|--------|
|두뇌 (Brain)|정보를 저장하고 통합하며, 의사결정을 내리는 시스템의 핵심 구성 요소|
|지각 (Perception)|모델의 지각 능력을 확장하여 텍스트, 음성, 영상 등 다양한 모달리티로부터 정보를 획득할 수 있게 하는 구성 요소|
|행동 (Action)|모델이 도구를 활용해 주변 환경을 바꾸거나 환경의 변화에 반응하여 대응할 수 있도록 하는 구성 요소|

<p align="center">
  <img src="https://github.com/user-attachments/assets/cf1cf589-3130-4025-ab72-176b21a73c08"><br>
  <b>Figure 1. 두뇌, 지각, 행동으로 구성된 LLM 기반 에이전트의 개념적 프레임워크 [1]</b> 
</p>

- LLM은 Agent 시스템에서 **두뇌 역할**을 수행
    - 지각과 행동을 위한 다양한 도구의 연동을 통해 능력 확장 <br>

ex) 멀티모달 입력을 통해 다양한 정보를 통합할 수 있고, 인터넷 연결을 통해 실시간 데이터를 수집하거나 전자상거래 시스템과 연동해 실제 거래를 수행
- LLM은 CoT나 기타 프롬프트 기법을 통해 추론 능력을 강화할 수 있다.
    - CoT: 환경으로부터 받은 피드백을 반영하는 방식으로, **에이전트를 반응형 시스템으로 발전시키는데 핵심적인 역할**을 함
- 인-컨텍스트 러닝을 통해 학습된 능력을 새로운 작업에 일반화할 수 있다.

### 1.2. LLM 기반 에이전트의 핵심 속성

|핵심 속성|내용|
|--|----|
|자율성 (Autonomy)|인간의 개입 (명확한 단계나 설명 등) 없이도 독립적으로 작업을 수행할 수 있어야 하며, 때때로 창의적인 방식으로 문제 해결 능력도 포함됨.|
|반응성 (Reactivity)|외부 환경의 변화를 인지하고 즉각적으로 반응할 수 있어야 함.|
|능동성 (Pro-activeness)|환경 변화에 대응하여 추론하고 계획을 세움으로써, 단순히 반응만 하는 것이 아닌 목표 지향적이어야 함.|
|사회적 능력 (Social ability)|LLM 대화 능력을 기반으로, 서로 다른 목표를 가진 다수의 에이전트와 소통 및 협력(업)할 수 있어야 함.|

**Paper** Generative Agents: Interactive Simulacra of Human Behavior [[**Youtube**](https://youtu.be/ZdoU9vI2yCg?si=5QezK1iEwEro8In_)][[**Web**](https://programs.sigchi.org/uist/2023/program/content/126779)][[**Paper**](https://dl.acm.org/doi/10.1145/3586183.3606763)]

### 1.3. 두뇌
**개념**: 정보를 저장하고 탐색하며 추론과 의사결정을 담당하는 시스템의 핵심 구성 요소

- 인간과의 상호작용이 자연어로 이루어져, <b><u>문제가 발생했을 때 과정을 관찰하고 모니터링을 할 수 있는</u> 중요한 장점을 제공.</b>
- 대화 능력이 부족할 시, 인간은 에이전트와의 상호작용에서 쉽게 좌절할 수 있으므로 <b><u>다양한 주제 및 복잡한 구조 이해, 과거 대화 이력 기반 논리적 대화 유지 등</b> 명확한 의사소통 능력이 필수</u>.
- 모델은 지시를 이해하고 들어오는 정보를 파악해 통합하며, 작업에 맞는 적절한 응답을 생성해야 함.
- 최근 몇 년간 정렬 기법, 지시 튜닝 덕에 대화 능력이 비약적으로 발전.

#### 1.3.1. 지식
|구분|내용|
|---|------|
|언어 지식|언어의 의미론과 구문론에 관한 지식|
|상식 지식|대부분의 사람이 알고 있는 일반적인 규칙과 사실의 집합. 프롬프트나 컨텍스트에 <u>구체적으로 언급하지 않더라도 <b>모델의 정확한 작업 수행에 필수</b></u>|
|도메인 지식|특정 전문 분야나 기술 분야에 특화된 지식.|

:bookmark: LLM의 지식은 사전 학습 시점에 고정되어있어, 지속 학습을 통해 새로운 정보를 습득하거나 사용자와의 이전 대화를 기억할 수 없다.

정보를 보유하는 것만으로 `두뇌`라 부를 수 없다. 에이전트라면 `추론`과 `계획` 능력을 갖춰야한다. 이를 가능하게 하는 것이 `CoT`와 `자기 일관성` 기법이다.<br>

#### 1.3.2. 계획

|단계|과제|내용|
|-|----|------|
|1|계획 수립 (Plan formulation)|모델이 <u>작업을 하위 작업으로 분해</u>한다. 접근 방식에 따라 LLM은 작업을 단계별로 나누고 이를 순차적으로 실행하기도 함.|
|2|계획 성찰 (Plan reflection)|<u>수립한 계획을 평가하고 피드백을 분석</u>하는 단계이다.|

#### 1.3.3. AI Agent의 두뇌를 위한 LLM 선택 고려사항
- LLM이 여러 개 있는 상황을 가정
    - 모델을 선택할 때는 메모리나 저장 공간의 제약을 고려해야 함.
    - 추론 속도는 사용자 경험에 큰 영향을 미침.
        - 추론 속도가 느릴 시, 사용자 경험 저하될 수 있음.

∴ 초당 생성 토큰 수 및 파라미터 수 대비 성능 등을 기준으로 벤치마크 평가 수행

**AI Agent의 두뇌로 사용할 LLM을 선택할 때 고려해야 할 주요 사항을 정리**
|구분|내용|
|-|-|
|모델 유형 결정|API 기반 폐쇄형 모델 (GPT-4, Claude 등) 또는 오픈소스 모델 (Mistral, LLaMA 등)|
|유지보수|LLM 관련 시스템을 클라우드나 온프레미스 환경에 배포해야 하며, <u>파라미터 수가 클수록 운영 비용이 증가한다는 점도 고려</u>해야 함.|
|도메인 특화 모델|특정 분야의 작업을 수행해야 한다면 해당 도메인에 특화된 모델 필요|

### 1.4. 지각
**개념**: 텍스트 입력만 처리하여 시각, 청각 같은 감각 인식 능력이 부족한 부분을 다양한 모달리티를 통해 환경에서 실시간 정보를 얻고 변화에 대응하여 지각

#### 1.4.1. 시각
**이미지 캡셔닝 (Image Captioning)**: 다른 모델을 사용하여 이미지에 대한 캡션을 생성하고 이를 프롬프트에 삽입하여 추가 컨텍스트로 활용.
\- 캡셔닝 과정에서 정보 손실이 발생하여 <u>시각 정보의 복잡성을 제대로 표현하지 못하는 단점 존재</u>

**체화된 언어 모델 PaLM-E [2]**: 범용 멀티모달 언어 모델. 이미지와 텍스트를 임베딩 공간에 직접 통합하여 체화된 추론을 수행.

<p align="center">
  <img src="https://github.com/user-attachments/assets/f36066b0-19f4-4ff2-aa38-e7c4cc862351"><br>
  <b>Figure 2.  PaLM-E의 전체적인 Framework [2]</b> 
</p>

- <b><u>이미지 입력</u></b>은 <u>언어 토큰과 동일한 잠재 임베딩 공간에 삽입</u>되며, 임베딩 벡터가 트랜스포머 블록으로 전달되어 텍스트 입력처럼 처리된다.
- 파인튜닝 과정을 거치면서 다양한 모달리티 간의 정보를 연결하는 법을 학습한다.
- BLIP-2 처럼 <b>Q-Former 모듈만 학습</b>하는 방법
    - <u>훨씬 적은 파라미터를 가진 모듈만 학습하면 되므로 효율적</u>.
    - 새로운 학습에 노출되지 않는 LLM의 특성으로, 이전에 학습한 언어 지식을 잊어버리는 파괴적 망각 현상을 효과적으로 줄일 수 있음.
- <b><u>비디오 입력</u></b>은 시간 차원이 추가된 시각 입력으로 볼 수 있다.
- **Flamingo** [3]
    - 마스크드 메커니즘을 사용하여 모델이 미래 정보를 미리 보지 않고 순차적으로 학습하도록 설계
<p align="center">
  <img src="https://github.com/user-attachments/assets/2968b47a-05f3-4a7c-baf5-8ff4dce1e6dc"><br>
  <b>Figure 3.  Flamingo 구조 오버뷰 [3]</b> 
</p>

- <b><u>청각 입력</u></b>
    - 음성에는 발화 내용, 억양, 멈춤, 감정 등 비언어적 정보를 포함.
    - 환경 소음은 위험이나 사건을 감지하는 단서가 될 수 있음.

<p align="center">
  <img src="https://github.com/user-attachments/assets/bed0b7a2-eb00-4db6-a8b3-0062d758515a" /><br>
  <b>Figure 4.  Spectrographic analysis: (a) raw audio signal of dog sound, (b) Mel filterbank spectrogram, (c) phase encoded spectrogram. The regions indicated by blackboxes shows the differences between spectrum representation in (b) and (c). [4]</b> 
</p>

- 오디오와 관련한 다양한 작업을 다른 모델을 호출하여 수행할 수 있다.
    - 텍스트-오디오 변환, 음성 번역 및 인식, 음성 분리, 음성 추출 등

- <b>AudioGPT</b>

<p align="center">
  <img src="https://github.com/user-attachments/assets/114e2f35-a856-40c4-aa44-1ca7a89d1602" /><br>
  <b>Figure 5. AudioGPT 개요 [5]</b> 
</p>

### 1.5. 행동

&nbsp; 생명체는 환경으로부터 신호를 인지하고 해석한 뒤 적절한 반응을 선택한다. AI Agent 역시 이와 유사하다.

- 외부에서 들어온 신호는 통합
- LLM은 이를 바탕으로 작업 계획을 수립
- 이후 전용 행동 모듈이 실행
- 텍스트 응답 출력 (가장 기본적) - 본래 텍스트 생성 능력을 갖추고 있으므로 지시에 따라 답변 생성

#### 1.5.1 체화된 행동
**개념**: Agent를 물리적 세계로 확장하는 개념 <br>
- 체화 가설에 따르면, 인간의 지능은 단순히 지식을 습득하는 것이 아니라 <b><u>환경과 지속적으로 상호작용하고 피드백을 받는 과정에서 발달</b></u>함. <br>
- AGI를 실현하기 위해, <u>모델도 외부 세계와 직접 상호작용해야 함</u>.
    - 단순한 명령 수행을 넘어 환경을 실시간으로 모니터링할 수 있어야 함.
    - 복잡한 목표를 세울 수 있어야 함.
    - 그 목표를 향해 정교하게 행동할 수 있어야 함.
    
## 2. AI 에이전트 분류하기

### 2.1. 가상 환경의 에이전트와 체화된 에이전트의 구분
- 디지털 에이전트: 다양한 수준으로 가상 환경에서만 상호작용

|구분|내용|
|---|---|
|액션 에이전트|시뮬레이션이나 가상 세계에서 행동을 수행 (보통은 강화학습 기반)|
|인터랙티브 에이전트|액션 에이전트의 확장 개념. 세계와 직접 소통하며 이를 수정할 수 있다.|

- 시스템의 상호작용 범위를 결정한 후에는 <b><u>모델이 어떤 방식으로 행동을 계획할 것인지를 결정</b></u>해야 함.
    - 주어진 작업을 어떻게 새부 행동 단위로 나누고 무엇을 우선할지 결정
    - 본 교재에서는 작업 계획에 초점을 맞추어 가능한 접근 방식을 상위 수준에서 살펴봄.
- 에이전트는 작업을 다루기 쉬운 여러 하위 작업으로 나누어야 한다.

|접근|개념|내용|특징|
|---|---|-------|---|
|선분해 방식|LLM이 작업을 일련의 하위 목표로 먼저 분해한 뒤 이전 목표를 해결한 후 다음 목표에 대한 계획을 세우는 식으로 순차적으로 해결하는 방식|- "먼저 계획을 세워보자", "이제 계획을 실행하자"와 같은 두 가지 프롬프트 활용. <br>- 계획과 실행 과정을 두 단계로 진행하도록 유도.|- 할루시네이션을 줄일 수 있음 <br>- 초기에 계획을 고정하므로, 오류가 발생해도 중도 수정이 어렵다.|
|교차 분해 방식|작업 분해와 계획 수립을 교차하면서 진행|- 추론과 계획을 번갈아 수행하므로 모델의 계획 능력을 점진적으로 향상시킴<br>- 환경 변화에 따라 작업을 동적으로 조정|문제가 지나치게 복잡할 시, 결과를 내지 못한 채 생성 결과만 길어지는 추론-계획 연쇄에 빠질 위험이 있다.|

### 2.2. 다양한 작업 분해 방식

#### 2.2.1. 다중 계획 선택
**개념**: 하나의 작업에 대해 여러 개의 계획을 생성한 뒤, 다양한 알고리즘을 활용해 그중 최적의 행동 계획을 선택하는 방식

- 후보 계획을 평가하고 선택하는 다양한 방법
    - 다수결
    - 트리 탐색 알고리즘이나 강화학습 활용
    - 휴리스틱 알고리즘
- 여러 경로를 생성하는데 계산 비용이 많이 들고, 확률적 과정에 의존하기 때문에 일관성이 떨어질 수 있음

#### 2.2.2. 외부 플래너 지원 계획
**개념**: LLM과 별도의 외부 플래너를 통합하여 계획 수립을 보조.

- 예를 들어, 최적의 해결 경로를 식별하기 위해 심볼릭 플래너를 추가할 수 있다.
- 오늘날에는 LLM이 최적의 계획을 찾는 것을 돕는 훨씬 가벼운 신경망 기반의 뉴럴 플래너도 있다.

LLM은 느린 사색적 추론을 수행하고 <u>플래너는 빠른 반응을 보완</u>한다. <br>
\- 먼저 플래너로 빠른 계획을 수립하고 LLM이 이를 점검하고 오류를 수정하는 과정을 수행할 수 있음. <br>
\- 위와 같이 느린 사고, 빠른 사고를 교차 활용이 가능.

#### 2.2.3. 성찰 및 개선
**개념**: 교차 분해 방식의 확장. LLM이 생성, 피드백, 개선을 반복해서 수행하는 구조.

- 모델은 각 생성 단계 이후 스스로 피드백을 만들어내고, 이를 바탕으로 계획을 점진적으로 다듬는다.
- 더 발전된 형태에서는 별도의 평가자 모델을 두어 계획을 검증하고 추가 피드백을 제공하기도 한다.
- 또한 환경 변화까지 피드백 과정에 반영하면 시스템의 적응성과 유연성을 한층 높일 수 있다.
- 성찰 과정이 항상 목표 달성으로 이어지는 것은 아니며, 특히 과정이 지나치게 복잡할 경우 LLM이 끝없는 연쇄에 갇힐 수 있다.

#### 2.2.4. 메모리 증강 계획
**개념**: 외부 메모리 시스템을 활용해 에이전트의 의사 결정과 계획 능력을 강화하는 방식
**특징**: 모델의 현재 컨텍스트 길이의 한계를 극복하기 위함

이 접근법을 통해 에이전트는 과거 경험이나 관찰 정보, 연산 결과를 저장하고 회상하여 활횽할 수 있으며, 이를 바탕으로 복잡한 작업에서 성능을 개선할 수 있다.

#### 2.2.5. 검색 증강 생성
**개념**: 외부에서 필요한 정보를 검색해 모델의 생성 과정에 활용하는 기술

- RAG를 에이전트의 과거 경험을 저장하는 데 사용할 수 있다. 
- RAG를 이용하면 모델이 이전의 작업 계획이나 다른 해결책, 문제 해결에 도움이 되는 추가 정보를 활용할 수 있다.

#### 2.2.6. 이전 경험에 대한 파인튜닝
**특징**: 파인튜닝이 비용이 더 많이 들지만, 경험을 모델 내부에 내재화하여 후속 작업에 대한 일반화 능력을 높인다. <BR>
\- 반면, RAG는 비용이 적게 드는 장점이 있으나 검색에 정확성이 요구되며 찾아낸 과거 경험이 현재 작업과 충분히 관련 있어야 효과를 발휘한다는 제약이 있다. <BR>
\- 더 정교한 RAG는 인간의 기억 체계를 모방하기도 함.

## 3. 단일 에이전트와 다중 에이전트 시스템 이해하기

에이전트의 능력이 무엇인지 그리고 이를 어떻게 작업 수행에 활용할 수 있는지 파악하는 것은 매우 중요하다.

### 3.1. 단일 에이전트 시스템

#### 시나리오 정의

|구분|시나리오|예시|
|---|-------|---|
|작업 지향 배치|에이전트가 인간의 특정 작업을 보조하는 경우|GPT기반 챗봇, 다국어 번역, 요약, 문서 생성 작업, 코딩 도우미 등|
|혁신 지향 배치|과학 분야에서 자율 탐색의 잠재력을 보여준다.|창의적인 스토리 제작, 디자인 컨셉 생성, 논문 요약, 연구 설계 보조, 과학 데이터 분석 자동화 등|
|생애 주기 지향 배치|에이전트는 개방된 세상에서 장기적인 생존을 보장하기 위해 지속적으로 새로운 기술을 탐색, 학습 및 활용하는 능력을 갖는다.|Minecraft: [[**Youtube**](https://www.youtube.com/watch?v=xN7A4BOr2kk)] - 05:35|

<p align="center">
  <img src="https://github.com/user-attachments/assets/8ab2ecc9-ccd0-4ce2-b0a6-08f8507f8bf9" /><br>
  <b>Figure 6. 다양한 시나리오에서의 LLM 기반 에이전트 응용 [6]</b> 
</p>

- 인간은 책에서만 배우는 것이 아니라 다른 사람들과의 상호작용을 통해도 학습한다.
- 게다가 대부분의 작업은 협업을 통해 이루어지며, 자원이 제한된 상황에서는 분업이 훨씬 효율적이다.
- 이러한 점에서 여러 연구자들은 인공지능에도 같은 방식을 적용할 것을 제안함.

### 3.2. 다중 에이전트 시스템
**개념**: 여러 에이전트가 서로 협력하고 소통하는 구조
**특징**: 여러 LLM 에이전트들이 자연어로 대화하며 협력하기 때문에, 그들의 행동 과정을 인간도 비교적 쉽게 해석할 수 있다.
- 일부 접근법에서는 상호 보완적이며 정보를 공유할 수 있는 협력형 에이전트를 만드는데 초점을 맞춘다.
- 에이전트 간 상호작용은 일정한 규칙 아래 질서 있게 진행될 수도 있고, 각 에이전트가 자유롭게 의견을 내는 다소 무질서한 방식으로 이루어질 수도 있다.
- 에이전트들이 반드시 협력해야되는 것은 아님. 경쟁 구도에서 효과적인 경우도 있음 - AlphaGo

<p align="center">
  <img src="https://github.com/user-attachments/assets/45cd5e1c-8def-499f-891b-68d29539ccfd" /><br>
  <b>Figure 7. 다중 LLM 기반 에이전트 상호작용 시나리오. [6]</b> 
</p>

- 적대적 환경에서 에이전트들이 다른 에이전트로부터 피드백을 받고 이를 바탕으로 성능을 개선할 수 있음
- 인간의 목표와 에이전트의 목표가 일치할 때 서로 상호작용하면서 에이전트에게 중요한 피드백 정보를 제공하는 관계.
    - 불균등 상호작용: 인간이 자연어로 지시를 내리면, 에이전트가 이를 실행하는 방식
    - 균등 상호작용: 인간과 에이전트가 동등한 파트너십을 형성하는 패러다임

<p align="center">
  <img src="https://github.com/user-attachments/assets/dcbe3ba0-0937-499f-b186-47b7c6c8ee80" /><br>
  <b>Figure 8. 인간-에이전트 상호작용의 두 가지 패러다임 [6]</b> 
</p>

## 4. 검색하여 정보를 스스로 찾는 ReAct 에이전트 만들기

|파일|링크|비고|
|---|---|---|
|Test-ddgs.ipynb|[[**Link**](/ch-04-LLM으로%20웹%20스크래핑%20에이전트%20구축하기/Test-ddgs.ipynb)]|DuckDuckGoSearch 연동 테스트|
|ReAct.ipynb|[[**Link**](/ch-04-LLM으로%20웹%20스크래핑%20에이전트%20구축하기/ReAct.ipynb)]|교재에서는 GPT-4o 유료 API를 사용했으나, 그럴 돈 없어서 Gemini로 함|


## Reference
[1] Xi, Zhiheng, et al. "The rise and potential of large language model based agents: A survey." Science China Information Sciences 68.2 (2025): 121101.<br>
[2] Driess, Danny, et al. "Palm-e: An embodied multimodal language model." (2023).<br>
[3] Alayrac, Jean-Baptiste, et al. "Flamingo: a visual language model for few-shot learning." Advances in neural information processing systems 35 (2022): 23716-23736.<br>
[4] Tak, Rishabh N., Dharmesh M. Agrawal, and Hemant A. Patil. "Novel phase encoded mel filterbank energies for environmental sound classification." International Conference on Pattern Recognition and Machine Intelligence. Cham: Springer International Publishing, 2017.<br>
[5] Huang, Rongjie, et al. "Audiogpt: Understanding and generating speech, music, sound, and talking head." Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 21. 2024.<br>
[6] Xi, Zhiheng, et al. "The rise and potential of large language model based agents: A survey. arXiv 2023." arXiv preprint arXiv:2309.07864 10 (2025).<br>
[7] <br>
[8] <br>
[9] <br>
[10] <br>
[11] <br>
