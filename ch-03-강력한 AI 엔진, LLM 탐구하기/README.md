# 2장: 강력한 AI 엔진, LLM 탐구하기

핵심 주제: 초거대 트랜스포머를 방대한 데이터셋으로 학습시키기 위한 다양한 학습 기법 및 멀티모달 데이터를 위한 데이터 확장 기법 알아보기

- LLM의 진화 과정 살펴보기
- 지시 튜닝, 파인튜닝, 정렬
- 작고 효율적인 LLM 탐구하기
- 멀티모달 모델 탐구하기
- 할루시네이션과 윤리적 $\cdot$ 법정 쟁점 이해하기
- 프롬프트 엔지니어링

## 1. LLM의 진화 과정 살펴보기
<b>LLM (Large Language Model)의 정의</b>: 100억 개 이상의 파라미터를 가진 모델

인간의 언어를 이해하고 생성하는 것에 그치지 않고 코드 생성 등 더 다양한 능력을 갖추기 위해, 단순히 파라미터 수만 늘리는 것이 아니라 <u><b>방대한 양의 데이터로 학습</b>해야 한다.</u>

주어진 이전 문맥으로 다음 단어를 예측하는 문제 <b>자기회귀 언어 모델링</b>를 통해 학습된다.

#### 파라미터 수 증가 배경
- 학습 가능성: 스케일링 법칙에 따라, 파라미터 수가 많을수록 더 뛰어나 능력을 갖출 수 있음
- 표현력: 모델 내부에서 더 복잡한 수식을 표현할 수 있어 일반화 능력이 향상됨. 과적합 위험이 줄어듦.
- 기억력: 파라미터가 많아질수록 더 많은 지식 내재화

### 1.1. 스케일링 법칙
<b>핵심</b>: 모델 크기(파라미터 수), 데이터셋 크기, 컴퓨팅 자원(훈련 비용)이 커질수록 대형 언어 모델(LLM)의 성능이 예측 가능하게 향상된다는 원리 (손실 관점)
```
예시 문장: The sentiment of the sentence: 'I Like Pizza' is
예측 단어: 'positive' or 'negative'
```
#### 조건부 확률
$$
P(\rm{positive~~|~~The~sentiment~of~the~sentence:~'I~like~Pizza'~is})
$$
$$
P(\rm{negative~~|~~The~sentiment~of~the~sentence:~'I~like~Pizza'~is})
$$

|예시|설명|
|---|---|
|질의응답|주어진 질문에 대해 정답 (답변)으로 가장 적절한 토큰의 확률을 계산하는 문제|
|텍스트 요약|원문을 주고 요약문의 확률을 생성하는 문제|

```
질의응답: P(answer | question)
텍스트 요약: P(summary | original article)
```
언어 모델링을 활용하면 거의 모든 과제를 해결할 수 있다.

이러한 능력을 갖춘 LLM 학습을 위해, 특별히 구성된 초대형 데이터셋이 사용된다.
- GPT3 학습 데이터셋: Common Crawl(웹 크롤링 데이터, 4,100억 토큰), Books2 & Books2(도서 코퍼스, 각각 120억/550억 토큰), Wikipedia(30억 토큰)

#### 파라미터 수 결정 요인
|결정 요인|설명|
|----|-----|
|임베딩 레이어|트랜스포머 기반 언어 모델이 구사할 수 있는 모든 단어 각각을 벡터로 변환하여 만들어진 행렬. 이 벡터들은 전부 학습 가능하므로 모델의 전체 파라미터 수에 포함됨|
|Self Attention|여러 가중치 행렬을 포함, 컨텍스트 길이가 길어질수록 크기도 증가|
|깊이|트랜스포머 블록 수를 늘리면 파라미터 수도 직접적으로 증가|

#### 1.1.1. LLM 성능 결정 요인
- 모델 크기 (파라미터 수)
- 데이터 크기 (학습 데이터셋 규모)
- 연산 크기 (컴퓨팅 자원)

성능 향상 조건: 모델의 크기 증가, 학습 데이터셋 증가, 더 많은 에포크로 학습 수행

### OpenAI는 이 요인들을 스케일링 법칙으로 정리

파라미터 수 $N$, 데이터셋 크기 $D$, 연산량 $C$에 대한 손실 함수:
$$
\mathcal{L}(N)=\big( \frac{N_C}{N} \big)^{a_N}~~~~~~\mathcal{L}(D)=\big( \frac{D_C}{D} \big)^{a_D}~~~~~~\mathcal{L}(C)=\big( \frac{C_C}{C} \big)^{a_C}
$$

<p align="center">
  <img src="https://github.com/user-attachments/assets/110f1308-5f0d-4852-8ba8-29e397535783"><br>
  <b>Figure 1.</b> 연산량, 데이터셋, 모델 크기 증가에 따른 언어 모델링 성능 향상 [1]
</p>

- 스케일링 법칙을 통해 <b>비가역적 손실</b>과 <b>가역적 손실</b>로 분해하여, 학습 전부터 모델의 예상 성능을 추정할 수 있다.
- 손실을 줄이고 성능을 개선하기 위해 모델을 확장할 것인지, 데이터셋을 늘릴 것인지 사전에 결정할 수 있다.
- 단, 이 상수들은 모델의 아키텍처와 기타 학습 설정에 따라 달라질 수 있다.

#### 스케일링 법칙에 대한 지적사항
- OpenAI의 주장보다 토큰 수에 훨씬 더 민감하다는 지적
- 더 학습할 수 있는 여지가 있음에도, <u>적은 학습 데이터를 적은 토큰으로 학습하여 과소적합 상태일 가능성</u>
- 단순히 많은 양의 토큰이 아닌 양질의 토큰이 필요
- <u>모든 토큰이 동일하게 가치있는 것은 아님</u>
- 다른 모델이 생성한 토큰을 사용하는 것은 고도화된 형태의 지식 증류에 불과하다는 지적

#### 1.1.2. 합성 데이터
<b>정의</b>: 실제 데이터를 모방한, 인간이 생성하지 않은 데이터 (생성형 인공지능 기술을 기반으로 한 컴퓨팅 알고리즘 및 시뮬레이션을 통해 생성)

의료 데이터는 특히 법률에서 민감 정보로 규정하고 있는 만큼, 많은 학습 데이터를 요구하는 의료 인공지능 분야에서 데이터 수집에 큰 어려움이 있음
- 가명화 프로세스의 등장에 의료 데이터 수집에 돌파구로 작용할 것으로 기대를 한 몸에 받았으나, <u>각종 사용 규제 및 가명화된 의료 데이터 재식별 위험 등의 문제</u>로 여전히 어려움이 있음

### 프라이버시와 규제로부터 비교적 자유로울 수 있는 의료 합성 데이터가 주목

<br>

<p align="center">
  <img src="https://github.com/user-attachments/assets/649dc591-d509-445b-9f9b-45cae6609d7e"><br>
  <b>Figure 2.</b> 실제 흉부 X-ray와 합성 흉부 X-ray [2]
</p>

합성 데이터는 원데이터로 재식별되지 않도록 가능성을 최소화하여 가명화 이전 정보에 대한 <b>역추적 위험이 훨씬 적기 때문에</b> 정보 보호 문제로부터 비교적 자유롭다. 

<b>희귀하여 수집이 어려운 데이터</b> 등의 임상 데이터를 <b>합성 데이터를 통해 충분항 양으로 수집 가능하며 이를 통해 <u>부족한 다양성의 문제를 해결할 수 있다</b>는 데에 긍정적</u>이다.

### GAN (Generative Aversarial Network) (Reference)
<hr>
None
<hr>

데이터 확보의 한계를 절대적으로 해결할 수 있을 것 같은 이 '<b>합성 데이터</b>'에도 문제가 존재함.
- 모델 붕괴 - 모델 성능이 급격하게 저하되는 현상 <br>
→ <B>사람의 창작물이 아닌</B> AI가 생성한 결과물로 채워지고, AI는 이를 통해 스스로 학습함으로써 <B>창의성 상실 및 품질 저하 발생</B>
- 파괴적(파멸적) 망각 - 이미 학습했던 일부 기술을 잊어버리는 현상

그럼에도 스케일링 법칙은 <u>여전히 중요한 의미를 지닌다.</u>

1,000억 개 이상의 파라미터를 갖는 대형 모델을 위한 설계, 시간, 비용 측면에서 방대한 투자가 필요하므로, 소형 모델로 실험하는 것이 합리적

최근, 특정 작업에 최적화된 맞춤형 스케일링 법칙 연구가 활발하다.

ex) [Code assistant model] → 전체 성능보다 코드 관련 과제에 대한 성능이 더 중요

### 1.1.3. 창발적 특성
<b>개념</b>: 작은 모델에서는 안나타나는 현상이 일정 규모에 도달하면 갑작스럽게 발현되는 특성<br>
\- 모델은 일정 크기에 도달하기 전까지는 창발적 능력이 무작위 수준에 불과하다가 <b>임계 규모</b>에 도달하는 순간 본격적으로 발현 <br>
\- <b>상전이 현상</b>: 특정 임계정을 지나면서 거의 0에 가까웠던 성능이 최고 수준으로 급격히 향상 <br>
\- 보통 수학적 추론이나 다단계 추론처럼 복잡한 과제에서 발생. <br>
\- <b>충분히 큰 모델을 만들어야 하는 필요성을 뒷받침. </b><br>

<p align="center">
  <img src="https://github.com/user-attachments/assets/ecdf2d7d-e5d3-4cec-8dbe-dadbff67628b"><br>
  <b>Figure 3.</b> 다양한 LLM 계열에서 발생하는 창발적 특성 현상 [3]
</p>

### 1.1.4. 컨텍스트 길이
LLM은 일정 크기의 청크, 고정된 크기의 컨텍스트 윈도우 단위로 텍스트를 입력 받아 처리한다. <br>
<b>컨텍스트 길이</b>: 모델이 한 번에 처리할 수 있는 정보의 양을 결정. 길어질수록 텍스트 내 장거리 의존성을 포착하는데 유리하며, 이는 여러 특정 작업에서 성능 향상으로 이어짐.

- <b>문서 요약</b>: 더 많은 컨텍스트를 반영해 일관되고 간결한 요약을 생성하며, 문서 전체에 걸쳐 엔티티와 그 관계를 파악.
- <b>질의응답</b>: 정답에 이르는 복잡한 관계를 추적할 수 있으며, <u>멀티-턴 대화에서도 이전 질문과 답변을 기억</u>.
- <b>언어 번역</b>: 특히 긴 문서나 복잡한 뉘앙스가 있을 때 맥락을 더 잘 유지함. 컨텍스트 길이가 길면 전문 문서, 기술 용어, 다의어, 약어 등을 번역하는 데 도움이 됨
- <b>대화형 AI</b>: <u>대화 전체 흐름을 더 정확히 추적하며 자연스러운 상호작용을 유지</u>함.

### 1.1.5. 전문가 혼합
개념 (MoE; Mixture of Experts): <u><b>연산 비용이 제한된 상황</u></b>에서 더 큰 모델을 적은 학습 단계로 훈련하기 위해, <u>동일한 연산 비용으로 모델을 확장</u>할 수 있게 해주는 기법

|구성 요소|설명|
|-|-|
|희소 MoE 레이어|각 레이어는 여러 전문가로 구성되며, 각 전문가는 하나의 신경망이다. 가장 단순한 형태는 Feedforward Network이다.|
|게이트 네트워크/라우터|입력 데이터를 어떤 전문가에게 보낼지를 결정한다. LLM의 경우 라우터는 특정 토큰을 하나 이상의 전문가에게 분배한다. 라우터 자체도 학습 가능한 파라미터를 가지며, 사전 학습 과정에서모델의 다른 부분과 함께 훈련된다.|

<p align="center">
  <img src="https://github.com/user-attachments/assets/43251afc-ee42-41af-9e68-fa59533cf7fc"><br>
  <b>Figure 4.</b> MoE 레이어의 예시 [4]
</p>

<hr>
<b>그림 설명</b>
<hr>

<b>MoE 희소 연산의 장점</b>
- 사전 학습 속도가 밀집 모델 (전통적인 트랜스포머)보다 빠르며, <u>추론 단계에서 모든 전문가를 동시에 사용할 필요가 없어 속도가 빠름</u>.
- 시스템이 유연하여 복잡한 분포를 처리할 수 있고, <u>각 전문가는 특정 하위 도메인에 특화</u>될 수 있음.
- 필요에 따라 전문가를 더 추가할 수 있어 확장성이 뛰어남.
- (<b>집단 지성</b>) <u>여러 전문가의 예측을 평균 내어 더 나은 일반화 성능을 얻을 수 있음</u>.

<b>MoE 희소 연산의 단점</b>
- <u>모든 전문가를 메모리에 적재해야 하므로 VRAM 사용량이 큼.
- 학습이 더 복잡하고 과적합을 일으킬 수 있음.
- 별도의 조치가 없다면 모델이 두세 개의 인기 있는 전문가만 사용할 위험이 큼.
- 파인튜닝이 어려움.
- 구성 요소가 늘어남에 따라 모델의 해석 가능성이 더 복잡해짐.</u>

### 최근, GPT-4, Gemini와 같은 대규모 모델 상당 수가 MoE 구조를 채택하고 있음.

## 2. 지시 튜닝, 파인튜닝, 정렬
<b>전통적인 파인튜닝</b>: 모델의 가중치를 특정 작업이나 새로운 도메인에 맞게 조정하는 과정 <br>
<u>1,000억 개가 넘는 파라미터를 가진 대규모 모델의 모든 파라미터를 학습하는 것보다 1억개만 학습하고도 유사한 효과를 내는 것</u>이 인프라와 비용 차원에서 효율적이다.

모델 대부분의 가중치를 동결한 상태에서 일부 가중치만 파인튜닝을 수행할 방법이 필요하다.

### 2.1. 내재 랭크 가설
<b>핵심</b>: 신경망에서 일어나는 중요한 변화를 저차원 표현으로도 충분히 포착할 수 있다는 것
$$
Y=W'X~~이때~~W'=W+\Delta W
$$
$\Delta W$는 파인튜닝 과정에서 업데이트 되는 가중치 변화. <BR>
내재 랭크 가설에 따르면, <u>$\Delta W$의 모든 요소가 중요한 것은 아니므로</u>, $\Delta W$를 더 작은 차원의 두 행렬 $A$와 $B$의 곱으로 표현할 수 있다. 이로 인해, 기존 모델의 가중치는 그대로 동결한 채, <b><u>이 두 행렬만 학습하면 된다</u></b>.
$$
Y=W'X~~여기서~~W'=W+BA
$$

#### 2.1.1. 행렬 분해

#### 2.1.2. LoRA: 딥러닝에서의 행렬 분해

#### 2.1.3. LoRA 학습의 주요 장점
- 학습 효율이 뛰어나다.
- 추론 단계에서 연산 비용이 증가하지 않는다.
- 기존 모델의 원래 능력을 훼손하지 않는다.
- 다양한 애플리케이션과 도메인에 맞춘 변화 행렬을 별도로 만들 수 있다.

### 2.2. 어댑터 추가 방식

### 2.3. 파라미터 훈련 없이 파인튜닝하는 기법
#### 2.3.1. 프롬프트 튜닝
#### 2.3.2. 프리픽스 튜닝


## Reference
[1] Kaplan, Jared, et al. "Scaling laws for neural language models." arXiv preprint arXiv:2001.08361 (2020).<br>
[2] 주인이 없는 의료 데이터가 주목받는 이유, brunch, [online] https://brunch.co.kr/@3b8bf521dd714f7/6 (Accessed 20th Jan)<br>
[3] Wei, Jason, et al. "Emergent abilities of large language models." arXiv preprint arXiv:2206.07682 (2022).<br>
[4] Fedus, William, Barret Zoph, and Noam Shazeer. "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity." Journal of Machine Learning Research 23.120 (2022): 1-39.<br>